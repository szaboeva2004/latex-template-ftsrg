{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5cdedcbd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting processing. Output will be saved to successful_runs_w_results.csv...\n",
      "Processing complete.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import csv\n",
    "import xml.etree.ElementTree as ET\n",
    "\n",
    "# --- Configuration ---\n",
    "# Folder containing the XML files. \n",
    "# Update this if your XMLs are in a different location relative to the script.\n",
    "DATA_FOLDER = \"result_xmls\" \n",
    "OUTPUT_FILE = \"successful_runs_w_results.csv\"\n",
    "\n",
    "# The list of (Algorithm Name, BTOR2 XML Path, C XML Path) pairs\n",
    "PAIRS = [\n",
    "    (\"CEGAR_PRED\", \n",
    "     os.path.join(DATA_FOLDER, \"btor2-algos-opt.2025-12-07_02-16-12.results.btor2-pred-cegar.btor2-pred.xml\"), \n",
    "     os.path.join(DATA_FOLDER, \"c-algos.2025-12-07_02-30-26.results.c-pred-cegar.c-pred.xml\")),\n",
    "    (\"CEGAR_EXPL\", \n",
    "     os.path.join(DATA_FOLDER, \"btor2-algos-opt.2025-12-07_02-16-12.results.btor2-expl-cegar.btor2-expl.xml\"), \n",
    "     os.path.join(DATA_FOLDER, \"c-algos.2025-12-07_02-30-26.results.c-expl-cegar.c-expl.xml\")),\n",
    "    (\"BMC\", \n",
    "     os.path.join(DATA_FOLDER, \"btor2-algos-opt.2025-12-07_02-16-12.results.btor2-bounded.btor2.xml\"), \n",
    "     os.path.join(DATA_FOLDER, \"c-algos.2025-12-07_02-30-26.results.c-bounded.c.xml\")),\n",
    "    (\"IMC\", \n",
    "     os.path.join(DATA_FOLDER, \"btor2-algos-opt.2025-12-07_02-16-12.results.btor2-imc.btor2.xml\"), \n",
    "     os.path.join(DATA_FOLDER, \"c-algos.2025-12-07_02-30-26.results.c-imc.c.xml\")),\n",
    "    (\"K-Induction\", \n",
    "     os.path.join(DATA_FOLDER, \"btor2-algos-opt.2025-12-07_02-16-12.results.btor2-kind.btor2.xml\"), \n",
    "     os.path.join(DATA_FOLDER, \"c-algos.2025-12-07_02-30-26.results.c-kind.c.xml\")),\n",
    "]\n",
    "\n",
    "def parse_benchmark_xml(xml_path, algorithm, input_type, csv_writer):\n",
    "    \"\"\"\n",
    "    Parses a single XML benchmark result file and writes successful runs to the CSV.\n",
    "    \"\"\"\n",
    "    if not os.path.exists(xml_path):\n",
    "        print(f\"Warning: File not found: {xml_path}\")\n",
    "        return\n",
    "\n",
    "    try:\n",
    "        tree = ET.parse(xml_path)\n",
    "        root = tree.getroot()\n",
    "\n",
    "        # BenchExec results store individual test runs in <run> tags\n",
    "        for run in root.findall('run'):\n",
    "            # We assume a run is successful if we find a column category=\"correct\"\n",
    "            is_successful = False\n",
    "            cpu_time = None\n",
    "            memory = None\n",
    "\n",
    "            # Iterate through columns to find status, cputime, and memory\n",
    "            for column in run.findall('column'):\n",
    "                title = column.get('title')\n",
    "                value = column.get('value')\n",
    "\n",
    "                if title == 'category' and value == 'correct':\n",
    "                    is_successful = True\n",
    "                elif title == 'cputime':\n",
    "                    cpu_time = value\n",
    "                elif title == 'memory':\n",
    "                    memory = value\n",
    "                elif title == 'status':\n",
    "                    status = value\n",
    "\n",
    "            if is_successful:\n",
    "                # Extract filename from the full path in the 'name' attribute\n",
    "                full_name = run.get('name', '')\n",
    "                file_name = os.path.basename(full_name)\n",
    "\n",
    "                # Write the row to CSV\n",
    "                csv_writer.writerow([\n",
    "                    file_name,\n",
    "                    input_type,\n",
    "                    algorithm,\n",
    "                    cpu_time,\n",
    "                    memory,\n",
    "                    status\n",
    "                ])\n",
    "\n",
    "    except ET.ParseError as e:\n",
    "        print(f\"Error parsing XML {xml_path}: {e}\")\n",
    "\n",
    "def main():\n",
    "    print(f\"Starting processing. Output will be saved to {OUTPUT_FILE}...\")\n",
    "    \n",
    "    with open(OUTPUT_FILE, mode='w', newline='', encoding='utf-8') as csvfile:\n",
    "        writer = csv.writer(csvfile)\n",
    "        # Write Header\n",
    "        writer.writerow(['Filename', 'Input Type', 'Algorithm', 'CPU Time', 'Memory', 'Result'])\n",
    "\n",
    "        for algo_name, btor2_xml_path, c_xml_path in PAIRS:\n",
    "            # Process the BTOR2 file (2nd element in tuple)\n",
    "            parse_benchmark_xml(btor2_xml_path, algo_name, \"BTOR2\", writer)\n",
    "            \n",
    "            # Process the C file (3rd element in tuple)\n",
    "            parse_benchmark_xml(c_xml_path, algo_name, \"C\", writer)\n",
    "\n",
    "    print(\"Processing complete.\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3aea08d0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting processing...\n",
      "Output will be saved to: xcfa_successful_runs.csv\n",
      "Processing BTOR2 file: xcfa_analyses\\fight-xcfa.2025-12-07_11-41-58.results.btor2-xcfa.btor2.xml\n",
      "Processing C file: xcfa_analyses\\fight-xcfa.2025-12-07_11-41-58.results.c-xcfa.c.xml\n",
      "Processing complete.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import csv\n",
    "import xml.etree.ElementTree as ET\n",
    "\n",
    "# --- Configuration ---\n",
    "# List of files to process. Each entry is a tuple: (File Path, Input Type Label)\n",
    "# We use raw strings (r\"...\") to safely handle the backslashes in the paths.\n",
    "FILES_TO_PROCESS = [\n",
    "    (r\"xcfa_analyses\\fight-xcfa.2025-12-07_11-41-58.results.btor2-xcfa.btor2.xml\", \"BTOR2\"),\n",
    "    (r\"xcfa_analyses\\fight-xcfa.2025-12-07_11-41-58.results.c-xcfa.c.xml\", \"C\")\n",
    "]\n",
    "\n",
    "OUTPUT_FILE = \"xcfa_successful_runs.csv\"\n",
    "\n",
    "def parse_and_append_results(xml_path, input_type_label, csv_writer):\n",
    "    \"\"\"\n",
    "    Parses a benchmark result file and appends successful runs to the CSV writer.\n",
    "    \"\"\"\n",
    "    # Check if file exists to avoid crashing\n",
    "    if not os.path.exists(xml_path):\n",
    "        print(f\"Warning: File not found: {xml_path}\")\n",
    "        return\n",
    "\n",
    "    try:\n",
    "        tree = ET.parse(xml_path)\n",
    "        root = tree.getroot()\n",
    "\n",
    "        # BenchExec results store individual test runs in <run> tags\n",
    "        for run in root.findall('run'):\n",
    "            is_successful = False\n",
    "            cpu_time = None\n",
    "            memory = None\n",
    "\n",
    "            # Iterate through columns to find status, cputime, and memory\n",
    "            for column in run.findall('column'):\n",
    "                title = column.get('title')\n",
    "                value = column.get('value')\n",
    "\n",
    "                # We determine success if the category is 'correct'\n",
    "                if title == 'category' and value == 'unknown':\n",
    "                    is_successful = True\n",
    "                elif title == 'cputime':\n",
    "                    cpu_time = value\n",
    "                elif title == 'memory':\n",
    "                    memory = value\n",
    "\n",
    "            if is_successful:\n",
    "                # Extract the filename from the 'name' attribute \n",
    "                # e.g., \"../../benchmarks/test.yml\" -> \"test.yml\"\n",
    "                full_name = run.get('name', '')\n",
    "                file_name = os.path.basename(full_name)\n",
    "\n",
    "                # Write the row: Filename, Input Type, CPU, Memory\n",
    "                csv_writer.writerow([\n",
    "                    file_name,\n",
    "                    input_type_label,\n",
    "                    cpu_time,\n",
    "                    memory\n",
    "                ])\n",
    "                \n",
    "    except ET.ParseError as e:\n",
    "        print(f\"Error parsing XML {xml_path}: {e}\")\n",
    "\n",
    "def main():\n",
    "    print(f\"Starting processing...\")\n",
    "    print(f\"Output will be saved to: {OUTPUT_FILE}\")\n",
    "    \n",
    "    with open(OUTPUT_FILE, mode='w', newline='', encoding='utf-8') as csvfile:\n",
    "        writer = csv.writer(csvfile)\n",
    "        \n",
    "        # Write Header\n",
    "        writer.writerow(['Filename', 'Input Type', 'CPU Time', 'Memory'])\n",
    "\n",
    "        # Loop through the files defined in configuration\n",
    "        for xml_path, label in FILES_TO_PROCESS:\n",
    "            print(f\"Processing {label} file: {xml_path}\")\n",
    "            parse_and_append_results(xml_path, label, writer)\n",
    "\n",
    "    print(\"Processing complete.\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "21c87ea8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Scanning directory: fight_xcfa\n",
      "Output will be saved to: xcfa_analysis_metrics.csv\n",
      "Done. Processed 1240 files.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import json\n",
    "import csv\n",
    "\n",
    "# --- Configuration ---\n",
    "# The root folder to start searching in. \n",
    "# Update this if your folder is named differently or located elsewhere.\n",
    "ROOT_FOLDER = \"fight_xcfa\"\n",
    "OUTPUT_CSV = \"xcfa_analysis_metrics.csv\"\n",
    "\n",
    "def count_stmt_labels(obj):\n",
    "    \"\"\"\n",
    "    Recursively counts the number of StmtLabel objects in a nested dictionary/list structure.\n",
    "    \"\"\"\n",
    "    count = 0\n",
    "    if isinstance(obj, dict):\n",
    "        # Check if this dictionary represents a StmtLabel\n",
    "        if obj.get('type') == 'hu.bme.mit.theta.xcfa.model.StmtLabel':\n",
    "            count += 1\n",
    "        # Recurse into all values\n",
    "        for v in obj.values():\n",
    "            count += count_stmt_labels(v)\n",
    "    elif isinstance(obj, list):\n",
    "        # Recurse into all items in the list\n",
    "        for item in obj:\n",
    "            count += count_stmt_labels(item)\n",
    "    return count\n",
    "\n",
    "def analyze_xcfa_json(file_path):\n",
    "    \"\"\"\n",
    "    Parses an xcfa.json file and returns the required metrics.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        with open(file_path, 'r', encoding='utf-8') as f:\n",
    "            data = json.load(f)\n",
    "\n",
    "        # 1. Variable Count (Global vars + Local vars in all procedures)\n",
    "        global_vars = len(data.get('vars', []))\n",
    "        local_vars = 0\n",
    "        \n",
    "        # 2. LOCs (Locations) & 3. Edges\n",
    "        total_locs = 0\n",
    "        total_edges = 0\n",
    "        \n",
    "        procedures = data.get('procedures', [])\n",
    "        for proc in procedures:\n",
    "            local_vars += len(proc.get('vars', []))\n",
    "            total_locs += len(proc.get('locs', []))\n",
    "            total_edges += len(proc.get('edges', []))\n",
    "            \n",
    "        total_vars = global_vars + local_vars\n",
    "\n",
    "        # 4. Atomic Stmts (Count of StmtLabels)\n",
    "        atomic_stmts = count_stmt_labels(data)\n",
    "\n",
    "        return {\n",
    "            \"vars\": total_vars,\n",
    "            \"locs\": total_locs,\n",
    "            \"edges\": total_edges,\n",
    "            \"stmts\": atomic_stmts\n",
    "        }\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"Error reading {file_path}: {e}\")\n",
    "        return None\n",
    "\n",
    "def main():\n",
    "    print(f\"Scanning directory: {ROOT_FOLDER}\")\n",
    "    print(f\"Output will be saved to: {OUTPUT_CSV}\")\n",
    "\n",
    "    results = []\n",
    "\n",
    "    # Walk through the directory tree\n",
    "    for root, dirs, files in os.walk(ROOT_FOLDER):\n",
    "        for file in files:\n",
    "            if file == \"xcfa.json\":\n",
    "                full_path = os.path.join(root, file)\n",
    "                \n",
    "                # --- Extract Metadata ---\n",
    "                \n",
    "                # 1. Name: The name of the folder containing the json\n",
    "                # e.g. .../adding.1.yml/xcfa.json -> adding.1.yml\n",
    "                folder_name = os.path.basename(root)\n",
    "                \n",
    "                # 2. Input Type: Check parent folders in the path\n",
    "                # Normalize path separators to handle Windows/Linux differences\n",
    "                norm_path = os.path.normpath(full_path)\n",
    "                path_parts = norm_path.split(os.sep)\n",
    "                \n",
    "                input_type = \"Unknown\"\n",
    "                if \"btor2-xcfa\" in path_parts:\n",
    "                    input_type = \"BTOR2\"\n",
    "                elif \"c-xcfa\" in path_parts:\n",
    "                    input_type = \"C\"\n",
    "                \n",
    "                # --- Analyze JSON Content ---\n",
    "                metrics = analyze_xcfa_json(full_path)\n",
    "                \n",
    "                if metrics:\n",
    "                    results.append([\n",
    "                        folder_name,\n",
    "                        metrics['vars'],\n",
    "                        metrics['locs'],\n",
    "                        metrics['edges'],\n",
    "                        metrics['stmts'],\n",
    "                        input_type\n",
    "                    ])\n",
    "                    # Optional: Print progress\n",
    "                    # print(f\"Processed: {folder_name} ({input_type})\")\n",
    "\n",
    "    # Write to CSV\n",
    "    with open(OUTPUT_CSV, 'w', newline='', encoding='utf-8') as f:\n",
    "        writer = csv.writer(f)\n",
    "        writer.writerow([\"Name\", \"Variable Count\", \"Locs\", \"Edges\", \"Atomic Stmts\", \"Input Type\"])\n",
    "        writer.writerows(results)\n",
    "\n",
    "    print(f\"Done. Processed {len(results)} files.\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8991dbec",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting log analysis...\n",
      "Output will be saved to: log_analysis_iterations.csv\n",
      "Scanning folder: opt_algos_logfiles\\btor2-algos-opt.2025-12-07_02-16-12.logfiles\n",
      "Scanning folder: opt_algos_logfiles\\c-algos.2025-12-07_02-30-26.logfiles\n",
      "Done. Processed 6970 log files.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import csv\n",
    "import re\n",
    "\n",
    "# --- Configuration ---\n",
    "# List of folders to scan for log files.\n",
    "# We use raw strings (r\"...\") to handle backslashes correctly.\n",
    "LOG_FOLDERS = [\n",
    "    r\"opt_algos_logfiles\\btor2-algos-opt.2025-12-07_02-16-12.logfiles\",\n",
    "    r\"opt_algos_logfiles\\c-algos.2025-12-07_02-30-26.logfiles\"\n",
    "]\n",
    "\n",
    "OUTPUT_FILE = \"log_analysis_iterations.csv\"\n",
    "\n",
    "def get_algorithm_type(filename):\n",
    "    \"\"\"\n",
    "    Deduces a readable Algorithm Type from the log filename.\n",
    "    \"\"\"\n",
    "    lower_name = filename.lower()\n",
    "    if \"pred-cegar\" in lower_name:\n",
    "        return \"CEGAR_PRED\"\n",
    "    elif \"expl-cegar\" in lower_name:\n",
    "        return \"CEGAR_EXPL\"\n",
    "    elif \"bounded\" in lower_name:\n",
    "        return \"BMC\"\n",
    "    elif \"kind\" in lower_name:\n",
    "        return \"K-Induction\"\n",
    "    elif \"imc\" in lower_name:\n",
    "        return \"IMC\"\n",
    "    else:\n",
    "        # Fallback: return the prefix before the first dot\n",
    "        return filename.split('.')[0]\n",
    "\n",
    "def parse_log_file(filepath):\n",
    "    \"\"\"\n",
    "    Parses a single log file to extract input name, type, and iterations.\n",
    "    \"\"\"\n",
    "    filename = os.path.basename(filepath)\n",
    "    \n",
    "    # 1. Extract Input File Name (benchmark name)\n",
    "    # Assumes format: [algo].[benchmark_name].log\n",
    "    # We try to strip the known algorithm prefixes if they exist, or just take the name.\n",
    "    try:\n",
    "        if filename.endswith(\".log\"):\n",
    "            base = filename[:-4] # Remove .log\n",
    "            # Split by first dot to separate the algo prefix (e.g., \"c-pred-cegar.\") \n",
    "            # from the actual file name (e.g. \"cambridge.5.yml\")\n",
    "            if '.' in base:\n",
    "                parts = base.split('.', 1)\n",
    "                # Heuristic: if the first part looks like an algo prefix, drop it\n",
    "                if any(x in parts[0] for x in ['btor2', 'c-', 'pred', 'expl', 'bounded', 'kind', 'imc']):\n",
    "                    benchmark_name = parts[1]\n",
    "                else:\n",
    "                    benchmark_name = base\n",
    "            else:\n",
    "                benchmark_name = base\n",
    "        else:\n",
    "            benchmark_name = filename\n",
    "    except Exception:\n",
    "        benchmark_name = filename\n",
    "\n",
    "    input_type = \"Unknown\"\n",
    "    max_iteration = 0\n",
    "\n",
    "    try:\n",
    "        with open(filepath, 'r', encoding='utf-8', errors='ignore') as f:\n",
    "            content = f.read()\n",
    "\n",
    "            # 2. Extract Input Type (from content)\n",
    "            # Looks for: --input-type VALUE\n",
    "            input_match = re.search(r'--input-type\\s+(\\w+)', content)\n",
    "            if input_match:\n",
    "                input_type = input_match.group(1)\n",
    "\n",
    "            # 3. Count Iterations\n",
    "            # Matches \"Iteration X\" (CEGAR) or \"Starting iteration X\" (BMC/Kind)\n",
    "            iteration_matches = re.findall(r'(?:Starting )?[Ii]teration\\s+(\\d+)', content)\n",
    "            \n",
    "            if iteration_matches:\n",
    "                iteration_nums = [int(num) for num in iteration_matches]\n",
    "                max_iteration = max(iteration_nums)\n",
    "            else:\n",
    "                # Fallback for BMC sometimes using \"Unrolling X\"\n",
    "                unroll_matches = re.findall(r'Unrolling\\s+(\\d+)', content)\n",
    "                if unroll_matches:\n",
    "                    max_iteration = max([int(num) for num in unroll_matches])\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"Error reading {filename}: {e}\")\n",
    "\n",
    "    # 4. Determine Algorithm Type from the filename\n",
    "    algo_type = get_algorithm_type(filename)\n",
    "\n",
    "    return {\n",
    "        \"Input Filename\": benchmark_name,\n",
    "        \"Input Type\": input_type,\n",
    "        \"Algorithm\": algo_type,\n",
    "        \"Iterations\": max_iteration\n",
    "    }\n",
    "\n",
    "def main():\n",
    "    print(\"Starting log analysis...\")\n",
    "    print(f\"Output will be saved to: {OUTPUT_FILE}\")\n",
    "\n",
    "    results = []\n",
    "\n",
    "    # Iterate over each folder in the list\n",
    "    for folder in LOG_FOLDERS:\n",
    "        print(f\"Scanning folder: {folder}\")\n",
    "        \n",
    "        if os.path.exists(folder):\n",
    "            for root, dirs, files in os.walk(folder):\n",
    "                for file in files:\n",
    "                    if file.endswith(\".log\"):\n",
    "                        full_path = os.path.join(root, file)\n",
    "                        data = parse_log_file(full_path)\n",
    "                        results.append(data)\n",
    "        else:\n",
    "            print(f\"Warning: Folder not found: {folder}\")\n",
    "\n",
    "    # Write results to CSV\n",
    "    if results:\n",
    "        headers = [\"Input Filename\", \"Input Type\", \"Algorithm\", \"Iterations\"]\n",
    "        \n",
    "        with open(OUTPUT_FILE, mode='w', newline='', encoding='utf-8') as csvfile:\n",
    "            writer = csv.DictWriter(csvfile, fieldnames=headers)\n",
    "            writer.writeheader()\n",
    "            writer.writerows(results)\n",
    "            \n",
    "        print(f\"Done. Processed {len(results)} log files.\")\n",
    "    else:\n",
    "        print(\"No log files found in the specified directories.\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
