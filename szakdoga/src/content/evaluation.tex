\chapter{Evaluation}\label{chapter:evaluation}

\section{Experiment Design}\label{sec:experiment_design}

This chapter presents a comprehensive evaluation of the BTOR2CFA transformation approach compared to the traditional translation-based workflow using Btor2C. The evaluation focuses on structural complexity, algorithm performance, and potential performance implications across multiple dimensions.

\subsection{Measurement Procedure} All experiments were conducted on virtual machines equipped with Intel Xeon (Skylake) processors, featuring between 2 and 32 cores operating at 2.2 GHz, and memory configurations ranging from 16 GB to 128 GB of RAM. The operating system used was Linux 6.8.0-60-generic, and all experiments were performed using \textsc{Theta} version 6.27.12. For SMT solving, I employed \textsc{MathSAT} version 5.6.10 \cite{Cimatti2013MathSAT5}.

To ensure reliable and reproducible performance measurements, we utilized the \textsc{RunExec} tool from the \textsc{BenchExec} suite \cite{BLW19}, a state-of-the-art benchmarking framework also used in the \textsc{SV-COMP} competition. Each experiment was executed with a CPU time limit of 900 seconds, a memory limit of 15 GB, and restricted to two CPU cores.

\subsection{Research Questions}

The evaluation aims to answer the following research questions:

\begin{description}
   \item[RQ1:] How does the structural complexity of the CFAs differ between direct \textsc{Btor2}-to-CFA transformation and the Btor2C translation approach?
   \item[RQ2:] Which model checking algorithms perform best for hardware verification, and how does input type (\textsc{Btor2} vs C) affect performance?
   \item[RQ3:] How does the structural complexity of the CFAs impact verification efficiency?
   \item[RQ4:] How does optimization of BTOR2CFA transformations impact verification efficiency?
\end{description}
% kevés iteráció alatt kijöna ahiba ha van mert a bad node az op után jön
% az hogy átírtam hibás vagy helyes eredményeknél segít jobban és melyik algoritmusnál?
\subsection{Benchmark Suite and Methodology}

The Hardware Model Checking Competition (HWMCC) provides a comprehensive suite of state-of-the-art benchmark models for evaluating hardware verification tools. In this work, I used a subset of these benchmarks selected according to the following criteria.

First, since my implementation focuses exclusively on safety property verification, only benchmarks containing the \verb|bad| property were considered. Benchmarks featuring liveness-related properties -- such as \verb|justice|, \verb|fair|, \verb|output|, and \verb|constraint| -- were excluded from the evaluation.

Secondly, as the current implementation of Theta (and consequently BTOR2CFA) does not support overflow predicate or reduce operations, benchmarks utilizing these features were excluded to ensure compatibility.

After applying these filtering criteria, a total of 698 benchmarks remained. The evaluation utilized both the \textsc{\textsc{Btor2}} and C benchmark subsets provided by HWMCC.

\paragraph{CFA Analysis}
For the complexity analysis, I first examined the Control-Flow Automata (CFAs) generated during the transformation process. It is important to note that the \textsc{c2XCFA} tool includes several optimizations, one of which is Large Block Encoding (LBE)~\cite{lbe}. For the purpose of a fair comparison, this optimization was disabled so that the directly transformed CFA would more closely align with the indirectly transformed one. Benchmarks that resulted in timeouts or memory exhaustion were excluded from the dataset. After filtering, 551 benchmarks remained, which provided a sufficiently representative basis for meaningful analysis.

\paragraph{Performance Analysis}
For the performance evaluation, I compared several verification algorithms supported by \textsc{Theta}. Specifically, I tested Counterexample-Guided Abstraction Refinement (CEGAR)~\cite{cegar} with both explicit-value and predicate abstraction, as well as Bounded Model Checking (BMC)~\cite{bmc}, k-Induction~\cite{kind}, Intrepolation-Based Model Checking (IMC)~\cite{imc}.
Each circuit was processed through both transformation workflows:

\begin{itemize}
    \item \textbf{Direct Approach}: \textsc{Btor2} $\rightarrow$ CFA (BTOR2XCFA)
    \item \textbf{Indirect Approach}: \textsc{Btor2} $\rightarrow$ C $\rightarrow$ CFA (Btor2C + Theta C frontend)
\end{itemize}

\section{Structural Complexity Analysis}\label{sec:structural}

The comparative analysis of the Control Flow Automata (CFA) derived from C sources versus those derived from BTOR2 descriptions reveals a counter-intuitive structural divergence, as illustrated in Figures \ref{fig:structural_comp} .

Complexity Overhead in C ParsingFigure \ref{fig:structural_comp} highlights the correlation between the atomic instruction counts of the two formats. Contrary to the expectation that low-level bit-vector logic would be more verbose, the data reveals that the C representation is significantly more complex. The data points cluster well below the $x=y$ diagonal (where $x$ is C), indicating that the high-level C parsing generates a substantially larger number of atomic instructions. This is likely due to the introduction of intermediate auxiliary variables and the explicit unrolling of high-level constructs during the translation from C to the CFA intermediate language.

Structural Inflation: Variables and Control Flow Figure xx breaks down the structural overhead, confirming that the C-XCFA transformation imposes a heavy tax on graph size. We observe that the C representation requires, on average, significantly more variables and locations than its BTOR2 counterpart.

This "inflation" in the C format can be attributed to the frontend's handling of memory and scope. While BTOR2 effectively encodes state using compact bit-vector arrays, the C frontend appears to instantiate distinct variables for intermediate calculation steps and memory addressing. Consequently, the BTOR2 format serves as a much more concise representation for verification tasks in this context.

\begin{table}[h]
\centering
\begin{tabular}{@{}llll@{}}
\toprule
Metric     & Average & Median & Std.\ Deviation \\ \midrule
Variables  & 0.3578  & 0.3569 & 0.0138          \\
Locations  & 0.6004  & 0.6000 & 0.0085          \\
Edges      & 0.7505  & 0.7500 & 0.0107          \\
Statements & 0.1782  & 0.1757 & 0.0153          \\ \bottomrule
\end{tabular}
\caption{Ratios of the generated CFAs for BTOR2\textbackslash C benchmarks.}
\end{table}


\begin{figure}
  \centering
  \includegraphics[width=1\textwidth]{figures/structural_comparison.png}
  \caption{Comparison of instruction counts showing the scale of complexity expansion between C2CFA and BTOR2CFA transformations.}
  \label{fig:structural_comp}
\end{figure}


\begin{table}
\centering
\small
\begin{tabular}{@{}lrrrrrrr@{}}
\toprule
Dataset &
\multicolumn{3}{c}{CPU Time (s)} &
\multicolumn{3}{c}{Memory (MB)} &
Success \\
\cmidrule(lr){2-4} \cmidrule(lr){5-7}
 & Avg & Median & SD & Avg & Median & SD & (\%) \\
\midrule
C2CFA     & 141.02 & 54.89 & 148.83 & 1878.00 & 984.34 & 2120.07 & 75.43 \\
BTOR2CFA  & 22.42  & 10.46 & 48.93  & 461.02  & 316.43 & 338.16  & 98.71 \\
\bottomrule
\end{tabular}
\caption{Summary of CPU time, memory usage, and success rate for the C2CFA and BTOR2CFA datasets.}
\label{tab:performance_summary}
\end{table}




%\textbf{3$\times$ more variables} 



\section{Algorithm Performance Analysis}\label{sec:algorithm}

%\subsection{Algorithmic Efficiency Impact}

\begin{figure}
  \centering
  \includegraphics[width=1.1\textwidth]{figures/comparison_fig_quantile_c_btor2.png}
  \caption{Quantile plots comparing the CPU time (left) and memory usage (right) of different model checking algorithms. The plots display the cumulative number of solved instances (x-axis) against the resources consumed (logarithmic y-axis) for both BTOR2 and C benchmark sets. Algorithms include CEGAR (Predictive and Explicit), BMC, IMC, and K-Induction.}
  \label{fig:performance_btor2_c}
\end{figure}

\begin{table}
\centering
\small
\begin{tabular}{@{}lrrrrrrr@{}}
\toprule
Algorithm &
\multicolumn{3}{c}{CPU Time (s)} &
\multicolumn{3}{c}{Memory (MB)} &
Success \\
\cmidrule(lr){2-4} \cmidrule(lr){5-7}
  & Avg & Median & SD & Avg & Median & SD & (\%) \\
\midrule
BMC         & 182.13 & 61.60 & 252.35 & 696.40  & 649.18 &  384.88    & 7.16 \\
CEGAR\_EXPL & \textbf{19.92}  & \textbf{14.47} & \textbf{13.43}  & \textbf{480.98}  & \textbf{405.40} &  \textbf{295.37}    & 3.58 \\
CEGAR\_PRED & 134.67 & 51.99 & 172.61 & 1717.04 & 859.59 &  1859.61    & \textbf{16.62} \\
IMC         & 159.21 & 52.98 & 216.72 & 1060.91 & 750.75 &  890.43    & 7.31 \\
K-Induction & 178.39 & 56.57 & 256.25 & 777.55  & 673.83 &  502.48    & 8.74 \\
\bottomrule
\end{tabular}
\caption{Summary of CPU time, memory usage, and success rate for algorithms using BTOR2 as input.}
\label{tab:btor2_input_summary}
\end{table}


\begin{table}
\centering
\small
\begin{tabular}{@{}lrrrrrrr@{}}
\toprule
Algorithm &
\multicolumn{3}{c}{CPU Time (s)} &
\multicolumn{3}{c}{Memory (MB)} &
Success \\
\cmidrule(lr){2-4} \cmidrule(lr){5-7}
  & Avg & Median & SD & Avg & Median & SD & (\%) \\
\midrule
BMC         & \textbf{171.63} & 23.76 & 277.89 & \textbf{1070.70} & 304.83  & \textbf{1892.30}     & 1.01 \\
CEGAR\_EXPL & 232.52 & \textbf{11.53} & 351.92 & 1696.30 & \textbf{297.23}  & 2270.82     & 1.01 \\
CEGAR\_PRED & 270.11 & 129.78& \textbf{259.44} & 4176.83 & 2990.98 & 3436.76     & \textbf{5.03} \\
IMC         & 283.48 & 149.17& 267.46 & 3314.08 & 3085.55 & 3201.35     & 1.87 \\
K-Induction & 187.27 & 49.03 & 268.60 & 2506.06 & 2686.79 & 2145.25     & 2.59 \\
\bottomrule
\end{tabular}
\caption{Summary of CPU time, memory usage, and success rate for algorithms using C as input.}
\label{tab:c_input_summary}
\end{table}


\begin{figure}
  \centering
  \includegraphics[width=1\textwidth]{figures/comparison_fig_quantile_btor2_opt_no_opt.png}
  \caption{Quantile plots comparing the CPU time (left) and memory usage (right) of different model checking algorithms. The plots display the cumulative number of solved instances (x-axis) against the resources consumed (logarithmic y-axis) for both optimized BTOR2CFA and unoptimized transformations. Algorithms include CEGAR (Predictive and Explicit), BMC, IMC, and K-Induction.}
  \label{fig:performance_btor2_opt}
\end{figure}


\begin{figure}
  \centering
  \includegraphics[width=1\textwidth]{figures/correlation_btor2_algos.png}
  \caption{Feature correlation heatmaps for BTOR2 inputs. The subplots compare the internal dependencies of problem variables and their correlation with runtime and memory usage for BMC, CEGAR (Explicit/Predictive), IMC, and K-Induction configurations.}
  \label{fig:corr_btor2}
\end{figure}

\begin{figure}
  \centering
  \includegraphics[width=1\textwidth]{figures/correlation_c_algos.png}
  \caption{Feature correlation heatmaps for C inputs. The subplots compare the internal dependencies of problem variables and their correlation with runtime and memory usage for BMC, CEGAR (Explicit/Predictive), IMC, and K-Induction configurations.}
  \label{fig:corr_c}
\end{figure}


\begin{figure}
  \centering
  \includegraphics[width=1\textwidth]{figures/iterations_vs_output.png}
  \caption{Analysis of the relationship between solver iterations and resource consumption. The scatter plots (top and bottom-left) display CPU time and memory usage against iteration counts, with a linear regression line (dashed red) indicating the trend. Data points are distinguished by verification result (False/pink vs. True/gold). The bottom-right panel shows the distribution of iterations required for Safe (True) versus Unsafe (False) outcomes.}
  \label{fig:iter_ouput}
\end{figure}

\section{Detailed Answers to Research Questions}

This section provides a detailed discussion of the experimental results by directly answering the research questions that guided this evaluation.

\subsection{RQ1: How does the structural complexity differ between direct BTOR2CFA transformation and the Btor2C translation approach?}

\todo{write this section}


\subsection{RQ2: Which model checking algorithms perform best for hardware verification, and how does input type (\textsc{Btor2} vs C) affect performance?}

\todo{write this section}

\subsection{RQ3: How does the structural complexity of the CFAs impact verification efficiency?}

\todo{write this section}


\subsection{RQ4: How does optimization of BTOR2CFA transformations impact verification efficiency?}

\todo{write this section}
