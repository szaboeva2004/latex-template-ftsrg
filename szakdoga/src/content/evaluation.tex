\chapter{Evaluation}\label{chapter:evaluation}

\section{Experiment Design}\label{sec:experiment_design}

This chapter presents a comprehensive evaluation of the BTOR2CFA transformation approach compared to the traditional translation-based workflow using Btor2C. The evaluation focuses on structural complexity, algorithm performance, and potential performance implications across multiple dimensions.

\subsection{Measurement Procedure} All experiments were conducted on virtual machines equipped with Intel Xeon (Skylake) processors, featuring between 2 and 32 cores operating at 2.2 GHz, and memory configurations ranging from 16 GB to 128 GB of RAM. The operating system used was Linux 6.8.0-60-generic, and all experiments were performed using \textsc{Theta} version 6.27.12. For SMT solving, I employed \textsc{MathSAT} version 5.6.10 \cite{Cimatti2013MathSAT5}.

To ensure reliable and reproducible performance measurements, we utilized the \textsc{RunExec} tool from the \textsc{BenchExec} suite \cite{BLW19}, a state-of-the-art benchmarking framework also used in the \textsc{SV-COMP} competition. Each experiment was executed with a CPU time limit of 900 seconds, a memory limit of 15 GB, and restricted to two CPU cores.

\subsection{Research Questions}

The evaluation aims to answer the following research questions:

\begin{description}
   \item[RQ1:] How does the structural complexity differ between direct \textsc{Btor2}-to-CFA transformation and the Btor2C translation approach?
   \item[RQ2:] Which model checking algorithms perform best for hardware verification, and how does input type (\textsc{Btor2} vs C) affect performance?
   \item[RQ3:] How does optimization of BTOR2CFA transformations impact verification efficiency?
\end{description}

\subsection{Benchmark Suite and Methodology}

The Hardware Model Checking Competition (HWMCC) provides a comprehensive suite of state-of-the-art benchmark models for evaluating hardware verification tools. In this work, I used a subset of these benchmarks selected according to the following criteria.

First, since my implementation focuses exclusively on safety property verification, only benchmarks containing the \verb|bad| property were considered. Benchmarks featuring liveness-related properties -- such as \verb|justice|, \verb|fair|, \verb|output|, and \verb|constraint| -- were excluded from the evaluation.

Secondly, as the current implementation of Theta (and consequently BTOR2CFA) does not support overflow predicate or reduce operations, benchmarks utilizing these features were excluded to ensure compatibility.

After applying these filtering criteria, a total of 698 benchmarks remained. The evaluation utilized both the \textsc{\textsc{Btor2}} and C benchmark subsets provided by HWMCC.

\paragraph{CFA Analysis}
For the complexity analysis, I first examined the Control-Flow Automata (CFAs) generated during the transformation process. It is important to note that the \textsc{c2XCFA} tool includes several optimizations, one of which is Large Block Encoding (LBE)~\cite{lbe}. For the purpose of a fair comparison, this optimization was disabled so that the directly transformed CFA would more closely align with the indirectly transformed one. Benchmarks that resulted in timeouts or memory exhaustion were excluded from the dataset. After filtering, 551 benchmarks remained, which provided a sufficiently representative basis for meaningful analysis.

\paragraph{Performance Analysis}
For the performance evaluation, I compared several verification algorithms supported by \textsc{Theta}. Specifically, I tested Counterexample-Guided Abstraction Refinement (CEGAR)~\cite{cegar} with both explicit-value and predicate abstraction, as well as Bounded Model Checking (BMC)~\cite{bmc}, k-Induction~\cite{kind}, Intrepolation-Based Model Checking (IMC)~\cite{imc}.
Each circuit was processed through both transformation workflows:

\begin{itemize}
    \item \textbf{Direct Approach}: \textsc{Btor2} $\rightarrow$ CFA (BTOR2XCFA)
    \item \textbf{Indirect Approach}: \textsc{Btor2} $\rightarrow$ C $\rightarrow$ CFA (Btor2C + Theta C frontend)
\end{itemize}

\section{Structural Complexity Analysis}\label{sec:structural}

The comparative analysis of the Control Flow Automata (CFA) derived from C sources versus those derived from BTOR2 descriptions reveals a counter-intuitive structural divergence, as illustrated in Figures \ref{fig:analysis1} and \ref{fig:analysis2}.

Complexity Overhead in C ParsingFigure \ref{fig:analysis1} highlights the correlation between the atomic instruction counts of the two formats. Contrary to the expectation that low-level bit-vector logic would be more verbose, the data reveals that the C representation is significantly more complex. The data points cluster well below the $x=y$ diagonal (where $x$ is C), indicating that the high-level C parsing generates a substantially larger number of atomic instructions. This is likely due to the introduction of intermediate auxiliary variables and the explicit unrolling of high-level constructs during the translation from C to the CFA intermediate language.

Structural Inflation: Variables and Control FlowFigure \ref{fig:analysis2} breaks down the structural overhead, confirming that the C-XCFA transformation imposes a heavy tax on graph size. We observe that the C representation requires, on average, significantly more variables and locations than its BTOR2 counterpart.

This "inflation" in the C format can be attributed to the frontend's handling of memory and scope. While BTOR2 effectively encodes state using compact bit-vector arrays, the C frontend appears to instantiate distinct variables for intermediate calculation steps and memory addressing. Consequently, the BTOR2 format serves as a much more concise representation for verification tasks in this context.

\begin{figure}
  \centering
  \includegraphics[width=1\textwidth]{figures/cfa_anal1.png}
  \caption{Comparison of instruction counts showing the scale of complexity expansion between C2CFA and BTOR2CFA transformations.}
  \label{fig:analysis1}
\end{figure}

\begin{figure}
  \centering
  \includegraphics[width=1\textwidth]{figures/cfa_anal2.png}
  \caption{A side-by-side comparison of key graph metrics (Variables, Locations, Edges), illustrating the increased graph size of the C format.}
  \label{fig:analysis2}
\end{figure}

\begin{table}[]
\begin{tabular}{@{}llll@{}}
\toprule
         & Avg CPU Time (s) & Avg Memory (MB) & Success Rate (Non-Crash \%)                                                                   \\ \midrule
C2CFA    & 141.02           & 1878.00         & 75.43\%                                                                                       \\
BTOR2CFA & 22.42            & 461.02          & 98.71\%
\end{tabular}
\caption{\todo{Hihi}}
\label{tab:cfa_performance}
\end{table}


\textbf{3$\times$ more variables} 


These differences have direct implications for model checking performance:
\begin{itemize}
    \item \textbf{State Space Exploration:} The higher number of edges may exponentially increase the state space exploration complexity
    \item \textbf{Memory Usage:} Increased locations and variables directly impact memory requirements during analysis
    \item \textbf{Analysis Time:} More complex control flow structures may lead to longer verification times
\end{itemize}

\section{Algorithm Performance Analysis}\label{sec:algorithm}

\subsection{Algorithmic Efficiency Impact}

The performance results in \autoref{tab:algorithm_performance} demonstrate that:

\begin{itemize}
    \item \textbf{\textsc{Btor2} inputs enable faster convergence} across all algorithms, with CEGAR\_EXPL achieving 2.4$\times$ better performance score
    \item \textbf{Reduced structural complexity directly translates to lower CPU times}, particularly for explicit-state methods
    \item \textbf{The direct transformation preserves semantic patterns} that algorithms can exploit more effectively
\end{itemize}

The relationship between structural complexity and algorithm performance is clearly demonstrated by the correlation between the 3.46$\times$ higher complexity score for C representations (from \autoref{tab:main_proc_stats}) and the 2.4$\times$ worse performance score for C inputs (from \autoref{tab:algorithm_performance}).

\section{Detailed Answers to Research Questions}

This section provides a detailed discussion of the experimental results by directly answering the research questions that guided this evaluation.

\subsection{RQ1: How does the structural complexity differ between direct \textsc{Btor2}-to-CFA transformation and the Btor2C translation approach?}

\todo{write this section}


\subsection{RQ2: How does the structural complexity differ between direct \textsc{Btor2}-to-CFA transformation and the Btor2C translation approach?}

\todo{write this section}


\subsection{RQ3: How does optimization of BTOR2CFA transformations impact verification efficiency?}

\todo{write this section}
